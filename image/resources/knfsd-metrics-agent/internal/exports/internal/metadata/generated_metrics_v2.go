// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/model/pdata"
)

// MetricSettings provides common settings for a particular metric.
type MetricSettings struct {
	Enabled bool `mapstructure:"enabled"`
}

// MetricsSettings provides settings for exports metrics.
type MetricsSettings struct {
	NfsExportsTotalOperations MetricSettings `mapstructure:"nfs.exports.total_operations"`
	NfsExportsTotalReadBytes  MetricSettings `mapstructure:"nfs.exports.total_read_bytes"`
	NfsExportsTotalWriteBytes MetricSettings `mapstructure:"nfs.exports.total_write_bytes"`
}

func DefaultMetricsSettings() MetricsSettings {
	return MetricsSettings{
		NfsExportsTotalOperations: MetricSettings{
			Enabled: true,
		},
		NfsExportsTotalReadBytes: MetricSettings{
			Enabled: true,
		},
		NfsExportsTotalWriteBytes: MetricSettings{
			Enabled: true,
		},
	}
}

type metricNfsExportsTotalOperations struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nfs.exports.total_operations metric with initial data.
func (m *metricNfsExportsTotalOperations) init() {
	m.data.SetName("nfs.exports.total_operations")
	m.data.SetDescription("Total number of NFS operations received from clients")
	m.data.SetUnit("{operations}")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

func (m *metricNfsExportsTotalOperations) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNfsExportsTotalOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNfsExportsTotalOperations) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNfsExportsTotalOperations(settings MetricSettings) metricNfsExportsTotalOperations {
	m := metricNfsExportsTotalOperations{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricNfsExportsTotalReadBytes struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nfs.exports.total_read_bytes metric with initial data.
func (m *metricNfsExportsTotalReadBytes) init() {
	m.data.SetName("nfs.exports.total_read_bytes")
	m.data.SetDescription("Total bytes read by the NFS clients")
	m.data.SetUnit("By")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

func (m *metricNfsExportsTotalReadBytes) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNfsExportsTotalReadBytes) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNfsExportsTotalReadBytes) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNfsExportsTotalReadBytes(settings MetricSettings) metricNfsExportsTotalReadBytes {
	m := metricNfsExportsTotalReadBytes{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricNfsExportsTotalWriteBytes struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nfs.exports.total_write_bytes metric with initial data.
func (m *metricNfsExportsTotalWriteBytes) init() {
	m.data.SetName("nfs.exports.total_write_bytes")
	m.data.SetDescription("Total bytes wrote by the NFS clients")
	m.data.SetUnit("By")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

func (m *metricNfsExportsTotalWriteBytes) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNfsExportsTotalWriteBytes) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNfsExportsTotalWriteBytes) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNfsExportsTotalWriteBytes(settings MetricSettings) metricNfsExportsTotalWriteBytes {
	m := metricNfsExportsTotalWriteBytes{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user settings.
type MetricsBuilder struct {
	startTime                       pdata.Timestamp
	metricNfsExportsTotalOperations metricNfsExportsTotalOperations
	metricNfsExportsTotalReadBytes  metricNfsExportsTotalReadBytes
	metricNfsExportsTotalWriteBytes metricNfsExportsTotalWriteBytes
}

// metricBuilderOption applies changes to default metrics builder.
type metricBuilderOption func(*MetricsBuilder)

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pdata.Timestamp) metricBuilderOption {
	return func(mb *MetricsBuilder) {
		mb.startTime = startTime
	}
}

func NewMetricsBuilder(settings MetricsSettings, options ...metricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		startTime:                       pdata.NewTimestampFromTime(time.Now()),
		metricNfsExportsTotalOperations: newMetricNfsExportsTotalOperations(settings.NfsExportsTotalOperations),
		metricNfsExportsTotalReadBytes:  newMetricNfsExportsTotalReadBytes(settings.NfsExportsTotalReadBytes),
		metricNfsExportsTotalWriteBytes: newMetricNfsExportsTotalWriteBytes(settings.NfsExportsTotalWriteBytes),
	}
	for _, op := range options {
		op(mb)
	}
	return mb
}

// Emit appends generated metrics to a pdata.MetricsSlice and updates the internal state to be ready for recording
// another set of data points. This function will be doing all transformations required to produce metric representation
// defined in metadata and user settings, e.g. delta/cumulative translation.
func (mb *MetricsBuilder) Emit(metrics pdata.MetricSlice) {
	mb.metricNfsExportsTotalOperations.emit(metrics)
	mb.metricNfsExportsTotalReadBytes.emit(metrics)
	mb.metricNfsExportsTotalWriteBytes.emit(metrics)
}

// RecordNfsExportsTotalOperationsDataPoint adds a data point to nfs.exports.total_operations metric.
func (mb *MetricsBuilder) RecordNfsExportsTotalOperationsDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricNfsExportsTotalOperations.recordDataPoint(mb.startTime, ts, val)
}

// RecordNfsExportsTotalReadBytesDataPoint adds a data point to nfs.exports.total_read_bytes metric.
func (mb *MetricsBuilder) RecordNfsExportsTotalReadBytesDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricNfsExportsTotalReadBytes.recordDataPoint(mb.startTime, ts, val)
}

// RecordNfsExportsTotalWriteBytesDataPoint adds a data point to nfs.exports.total_write_bytes metric.
func (mb *MetricsBuilder) RecordNfsExportsTotalWriteBytesDataPoint(ts pdata.Timestamp, val int64) {
	mb.metricNfsExportsTotalWriteBytes.recordDataPoint(mb.startTime, ts, val)
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...metricBuilderOption) {
	mb.startTime = pdata.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op(mb)
	}
}

// Attributes contains the possible metric attributes that can be used.
var Attributes = struct {
}{}

// A is an alias for Attributes.
var A = Attributes
